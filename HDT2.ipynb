{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CC3092 - Deep Learning y Sistemas Inteligentes\n",
    "## Deep Learning y Sistemas Inteligentes\n",
    "## - Hoja de Trabajo 2 -\n",
    "\n",
    "## Integrantes: \n",
    "\n",
    " - Christopher García\n",
    " - Alejandro Gómez\n",
    " - Gabriel Vicente\n",
    "\n",
    "## Instrucciones:\n",
    "- Esta es una actividad en grupos de 3 personas máximo\n",
    "- No se permitirá ni se aceptará cualquier indicio de copia. De presentarse, se procederá según el reglamento\n",
    "correspondiente.\n",
    "- Tendrán hasta el día indicado en Canvas.\n",
    "Ejercicio 1 - Experimentación Práctica\n",
    "En esta actividad, implementará y comparará diferentes funciones de pérdida y técnicas de regularización\n",
    "utilizando PyTorch. Utilizará el conjunto de datos de Iris para una tarea de clasificación y una arquitectura básica de\n",
    "red neuronal de feedforward. El objetivo es observar cómo las diferentes opciones impactan la convergencia y el\n",
    "rendimiento del modelo.\n",
    "\n",
    "# Ejercicio 1 - Experimentación Práctica\n",
    "\n",
    "En esta actividad, implementará y comparará diferentes funciones de pérdida y técnicas de regularización\n",
    "utilizando PyTorch. Utilizará el conjunto de datos de Iris para una tarea de clasificación y una arquitectura básica de\n",
    "red neuronal de feedforward. El objetivo es observar cómo las diferentes opciones impactan la convergencia y el\n",
    "rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Preparación del conjunto de datos\n",
    "\n",
    "Cargue el conjunto de datos de Iris utilizando bibliotecas como sklearn.datasets. Luego, divida el conjunto de datos\n",
    "en conjuntos de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Librerias necesarias \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (120, 4)\n",
      "Tamaño del conjunto de validación: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load data \"\"\"\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", X_train.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", X_val.shape)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Arquitectura modelo\n",
    "Cree una red neuronal feedforward simple utilizando nn.Module de PyTorch. Luego, defina capa de entrada, capas\n",
    "ocultas y capa de salida. Después, elija las funciones de activación y el número de neuronas por capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleFeedforwardNN(\n",
      "  (input_layer): Linear(in_features=4, out_features=64, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (activation): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" RN simple usando pytorch modules \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleFeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(SimpleFeedforwardNN, self).__init__()\n",
    "\n",
    "        self.input_layer = nn.Linear(input_size, hidden_sizes[0])\n",
    "        \n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_sizes) - 1):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], output_size)\n",
    "        \n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = self.activation(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [64, 32]\n",
    "output_size = 3\n",
    "\n",
    "model = SimpleFeedforwardNN(input_size, hidden_sizes, output_size)\n",
    "print(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Funciones de Pérdida\n",
    "\n",
    "Utilice diferentes funciones de pérdida comunes como Cross-Entropy Loss y MSE para clasificación. Entrene el\n",
    "modelo con diferentes funciones de pérdida y registre las pérdidas de entrenamiento y test. Debe utilizar al menos 3\n",
    "diferentes funciones. Es decir, procure que su código sea capaz de parametrizar el uso de diferentes funciones de\n",
    "pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 1.0347, Val Loss: 0.9240\n",
      "Epoch [2/50], Train Loss: 0.8938, Val Loss: 0.8406\n",
      "Epoch [3/50], Train Loss: 0.8199, Val Loss: 0.7661\n",
      "Epoch [4/50], Train Loss: 0.7468, Val Loss: 0.6868\n",
      "Epoch [5/50], Train Loss: 0.6701, Val Loss: 0.6275\n",
      "Epoch [6/50], Train Loss: 0.6059, Val Loss: 0.5569\n",
      "Epoch [7/50], Train Loss: 0.5415, Val Loss: 0.5077\n",
      "Epoch [8/50], Train Loss: 0.4961, Val Loss: 0.4697\n",
      "Epoch [9/50], Train Loss: 0.4606, Val Loss: 0.4361\n",
      "Epoch [10/50], Train Loss: 0.4320, Val Loss: 0.4163\n",
      "Epoch [11/50], Train Loss: 0.4094, Val Loss: 0.3943\n",
      "Epoch [12/50], Train Loss: 0.3896, Val Loss: 0.3751\n",
      "Epoch [13/50], Train Loss: 0.3792, Val Loss: 0.3561\n",
      "Epoch [14/50], Train Loss: 0.3570, Val Loss: 0.3505\n",
      "Epoch [15/50], Train Loss: 0.3371, Val Loss: 0.3247\n",
      "Epoch [16/50], Train Loss: 0.3220, Val Loss: 0.3146\n",
      "Epoch [17/50], Train Loss: 0.3034, Val Loss: 0.3020\n",
      "Epoch [18/50], Train Loss: 0.2872, Val Loss: 0.2829\n",
      "Epoch [19/50], Train Loss: 0.2713, Val Loss: 0.2766\n",
      "Epoch [20/50], Train Loss: 0.2557, Val Loss: 0.2558\n",
      "Epoch [21/50], Train Loss: 0.2412, Val Loss: 0.2439\n",
      "Epoch [22/50], Train Loss: 0.2295, Val Loss: 0.2323\n",
      "Epoch [23/50], Train Loss: 0.2136, Val Loss: 0.2212\n",
      "Epoch [24/50], Train Loss: 0.1991, Val Loss: 0.2139\n",
      "Epoch [25/50], Train Loss: 0.1892, Val Loss: 0.1998\n",
      "Epoch [26/50], Train Loss: 0.1787, Val Loss: 0.1925\n",
      "Epoch [27/50], Train Loss: 0.1747, Val Loss: 0.1847\n",
      "Epoch [28/50], Train Loss: 0.1605, Val Loss: 0.1761\n",
      "Epoch [29/50], Train Loss: 0.1552, Val Loss: 0.1757\n",
      "Epoch [30/50], Train Loss: 0.1525, Val Loss: 0.1632\n",
      "Epoch [31/50], Train Loss: 0.1384, Val Loss: 0.1668\n",
      "Epoch [32/50], Train Loss: 0.1342, Val Loss: 0.1543\n",
      "Epoch [33/50], Train Loss: 0.1297, Val Loss: 0.1493\n",
      "Epoch [34/50], Train Loss: 0.1337, Val Loss: 0.1489\n",
      "Epoch [35/50], Train Loss: 0.1208, Val Loss: 0.1395\n",
      "Epoch [36/50], Train Loss: 0.1177, Val Loss: 0.1445\n",
      "Epoch [37/50], Train Loss: 0.1131, Val Loss: 0.1337\n",
      "Epoch [38/50], Train Loss: 0.1177, Val Loss: 0.1372\n",
      "Epoch [39/50], Train Loss: 0.1123, Val Loss: 0.1373\n",
      "Epoch [40/50], Train Loss: 0.1010, Val Loss: 0.1230\n",
      "Epoch [41/50], Train Loss: 0.1091, Val Loss: 0.1246\n",
      "Epoch [42/50], Train Loss: 0.1011, Val Loss: 0.1298\n",
      "Epoch [43/50], Train Loss: 0.1038, Val Loss: 0.1200\n",
      "Epoch [44/50], Train Loss: 0.0962, Val Loss: 0.1164\n",
      "Epoch [45/50], Train Loss: 0.0955, Val Loss: 0.1133\n",
      "Epoch [46/50], Train Loss: 0.1018, Val Loss: 0.1156\n",
      "Epoch [47/50], Train Loss: 0.0968, Val Loss: 0.1092\n",
      "Epoch [48/50], Train Loss: 0.1004, Val Loss: 0.1339\n",
      "Epoch [49/50], Train Loss: 0.0866, Val Loss: 0.1041\n",
      "Epoch [50/50], Train Loss: 0.0975, Val Loss: 0.1069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0346800009409587,\n",
       "  0.8937852541605632,\n",
       "  0.8198907891909282,\n",
       "  0.7468416770299275,\n",
       "  0.670071562131246,\n",
       "  0.6059257427851359,\n",
       "  0.5414753715197246,\n",
       "  0.49612850149472554,\n",
       "  0.4606103777885437,\n",
       "  0.43200918237368263,\n",
       "  0.40941513180732725,\n",
       "  0.3895662784576416,\n",
       "  0.379242742061615,\n",
       "  0.3570469816525777,\n",
       "  0.33709455529848736,\n",
       "  0.32198080817858377,\n",
       "  0.30337822834650674,\n",
       "  0.2872300366560618,\n",
       "  0.2713353981574376,\n",
       "  0.2557269970575968,\n",
       "  0.2411670724550883,\n",
       "  0.22946160236994426,\n",
       "  0.21359724700450897,\n",
       "  0.19912118911743165,\n",
       "  0.18915411904454232,\n",
       "  0.17871310114860534,\n",
       "  0.17467562158902486,\n",
       "  0.16050993502140046,\n",
       "  0.1552472561597824,\n",
       "  0.15252178435524305,\n",
       "  0.1384110152721405,\n",
       "  0.1341510981321335,\n",
       "  0.12973794639110564,\n",
       "  0.13367379754781722,\n",
       "  0.12077055325110754,\n",
       "  0.11770466963450114,\n",
       "  0.11314948250850042,\n",
       "  0.11766246172289054,\n",
       "  0.11233008652925491,\n",
       "  0.10095376918713252,\n",
       "  0.10912240991989772,\n",
       "  0.10109676023324331,\n",
       "  0.10383709371089936,\n",
       "  0.09624977658192317,\n",
       "  0.09548686345418295,\n",
       "  0.10184985150893529,\n",
       "  0.09677882517377535,\n",
       "  0.10041661908229192,\n",
       "  0.0866132602095604,\n",
       "  0.09748292515675226],\n",
       " [0.9239751855532329,\n",
       "  0.8405791322390238,\n",
       "  0.7660505016644795,\n",
       "  0.6868167678515117,\n",
       "  0.6274890303611755,\n",
       "  0.5569074749946594,\n",
       "  0.5077185014883677,\n",
       "  0.46966190338134767,\n",
       "  0.4361270070075989,\n",
       "  0.41626288096110026,\n",
       "  0.39426657756169636,\n",
       "  0.3751472632090251,\n",
       "  0.3560750146706899,\n",
       "  0.35048906604448954,\n",
       "  0.3246983528137207,\n",
       "  0.3145824750264486,\n",
       "  0.3019645114739736,\n",
       "  0.2828757067521413,\n",
       "  0.27661099235216774,\n",
       "  0.2557891656955083,\n",
       "  0.2439428319533666,\n",
       "  0.2323233852783839,\n",
       "  0.22119038204352062,\n",
       "  0.2139446755250295,\n",
       "  0.19980931878089905,\n",
       "  0.19248345792293547,\n",
       "  0.18474648694197338,\n",
       "  0.17613309025764465,\n",
       "  0.17567979792753854,\n",
       "  0.16317087511221567,\n",
       "  0.16675599614779155,\n",
       "  0.15432228843371074,\n",
       "  0.14929957836866378,\n",
       "  0.14886758625507354,\n",
       "  0.1394884611169497,\n",
       "  0.14447101553281147,\n",
       "  0.1337379738688469,\n",
       "  0.1371889462073644,\n",
       "  0.13728067576885222,\n",
       "  0.12303770730892817,\n",
       "  0.12461861073970795,\n",
       "  0.12978629320859908,\n",
       "  0.12002514600753784,\n",
       "  0.1164436807235082,\n",
       "  0.11325641771157582,\n",
       "  0.11558509369691213,\n",
       "  0.10918114085992177,\n",
       "  0.13385069966316224,\n",
       "  0.10407272577285767,\n",
       "  0.10688609778881072])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" Entrenamiento, funcion de perdida y registro \"\"\"\n",
    "\n",
    "def train_model(model, loss_fn, optimizer, num_epochs=50):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_sizes = [64, 32]\n",
    "output_size = 3\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "model = SimpleFeedforwardNN(input_size, hidden_sizes, output_size)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_model(model, loss_fn, optimizer, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
